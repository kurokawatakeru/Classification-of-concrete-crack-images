{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n",
      "PyTorch version: 2.5.1\n",
      "Device: mps\n",
      "\n",
      "Training model for surface type: D\n",
      "Total images: 13620\n",
      "Crack images: 2025\n",
      "No crack images: 11595\n",
      "Starting training on mps...\n",
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|██████████| 681/681 [10:26<00:00,  1.09it/s, loss=0.4013, acc=87.50] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3409 Acc: 88.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|██████████| 171/171 [00:50<00:00,  3.38it/s, loss=0.1705, acc=100.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3118 Acc: 89.57%\n",
      "\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|██████████| 681/681 [09:13<00:00,  1.23it/s, loss=0.2810, acc=87.50] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3052 Acc: 89.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|██████████| 171/171 [00:44<00:00,  3.81it/s, loss=0.0911, acc=100.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2845 Acc: 90.90%\n",
      "\n",
      "Training completed in 21m 16s\n",
      "Best val Acc: 90.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 171/171 [00:44<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully trained model for D\n",
      "\n",
      "Training model for surface type: P\n",
      "Total images: 24334\n",
      "Crack images: 2608\n",
      "No crack images: 21726\n",
      "Starting training on mps...\n",
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|██████████| 1217/1217 [31:29<00:00,  1.55s/it, loss=0.2183, acc=90.91]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2615 Acc: 90.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|██████████| 305/305 [00:50<00:00,  6.07it/s, loss=0.0400, acc=100.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2202 Acc: 92.97%\n",
      "\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|██████████| 1217/1217 [14:44<00:00,  1.38it/s, loss=0.0534, acc=100.00] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2266 Acc: 92.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|██████████| 305/305 [01:14<00:00,  4.11it/s, loss=0.0372, acc=100.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1927 Acc: 93.84%\n",
      "\n",
      "Training completed in 48m 19s\n",
      "Best val Acc: 93.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 305/305 [01:22<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully trained model for P\n",
      "\n",
      "Training model for surface type: W\n",
      "Total images: 18138\n",
      "Crack images: 3851\n",
      "No crack images: 14287\n",
      "Starting training on mps...\n",
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|██████████| 907/907 [12:10<00:00,  1.24it/s, loss=0.1874, acc=92.86] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3575 Acc: 86.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|██████████| 227/227 [00:55<00:00,  4.09it/s, loss=0.1074, acc=100.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2973 Acc: 87.93%\n",
      "\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Phase: 100%|██████████| 907/907 [11:41<00:00,  1.29it/s, loss=0.4189, acc=78.57] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3014 Acc: 88.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Phase: 100%|██████████| 227/227 [00:52<00:00,  4.34it/s, loss=0.0666, acc=100.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2809 Acc: 90.24%\n",
      "\n",
      "Training completed in 25m 41s\n",
      "Best val Acc: 90.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 227/227 [00:51<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully trained model for W\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from PIL import Image\n",
    "import time\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# データセットのパスを設定\n",
    "data_dir = 'SDNET2018'\n",
    "train_dir = {\n",
    "    'D': {\n",
    "        'crack': os.path.join(data_dir, 'D', 'CD'),\n",
    "        'uncrack': os.path.join(data_dir, 'D', 'UD')\n",
    "    },\n",
    "    'P': {\n",
    "        'crack': os.path.join(data_dir, 'P', 'CP'),\n",
    "        'uncrack': os.path.join(data_dir, 'P', 'UP')\n",
    "    },\n",
    "    'W': {\n",
    "        'crack': os.path.join(data_dir, 'W', 'CW'),\n",
    "        'uncrack': os.path.join(data_dir, 'W', 'UW')\n",
    "    }\n",
    "}\n",
    "\n",
    "# 結果保存用のディレクトリ作成\n",
    "os.makedirs('results', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# データ変換の定義\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "class CrackDataset(Dataset):\n",
    "    def __init__(self, crack_dir, uncrack_dir, transform=None):\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # ひび割れ画像の追加\n",
    "        for img_name in os.listdir(crack_dir):\n",
    "            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                self.image_paths.append(os.path.join(crack_dir, img_name))\n",
    "                self.labels.append(1)\n",
    "        \n",
    "        # 非ひび割れ画像の追加\n",
    "        for img_name in os.listdir(uncrack_dir):\n",
    "            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                self.image_paths.append(os.path.join(uncrack_dir, img_name))\n",
    "                self.labels.append(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_path = self.image_paths[idx]\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            label = self.labels[idx]\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {str(e)}\")\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, device, num_epochs=10):\n",
    "    print(f'Starting training on {device}...')\n",
    "    start_time = time.time()\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            total_samples = 0\n",
    "            \n",
    "            with tqdm(dataloaders[phase], desc=f'{phase.capitalize()} Phase') as pbar:\n",
    "                for inputs, labels in pbar:\n",
    "                    try:\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        \n",
    "                        optimizer.zero_grad()\n",
    "                        \n",
    "                        with torch.set_grad_enabled(phase == 'train'):\n",
    "                            outputs = model(inputs)\n",
    "                            _, preds = torch.max(outputs, 1)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                            \n",
    "                            if phase == 'train':\n",
    "                                loss.backward()\n",
    "                                optimizer.step()\n",
    "                        \n",
    "                        batch_loss = loss.item() * inputs.size(0)\n",
    "                        # CPUに移動してからnumpy/itemを使用\n",
    "                        batch_corrects = torch.sum(preds == labels.data).cpu().item()\n",
    "                        running_loss += batch_loss\n",
    "                        running_corrects += batch_corrects\n",
    "                        total_samples += inputs.size(0)\n",
    "                        \n",
    "                        current_loss = batch_loss / inputs.size(0)\n",
    "                        current_acc = (batch_corrects / inputs.size(0)) * 100\n",
    "                        pbar.set_postfix({\n",
    "                            'loss': f'{current_loss:.4f}',\n",
    "                            'acc': f'{current_acc:.2f}'\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error in batch: {str(e)}\")\n",
    "                        continue\n",
    "            \n",
    "            epoch_loss = running_loss / total_samples\n",
    "            epoch_acc = (running_corrects / total_samples) * 100\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                history['train_loss'].append(epoch_loss)\n",
    "                history['train_acc'].append(epoch_acc)\n",
    "            else:\n",
    "                history['val_loss'].append(epoch_loss)\n",
    "                history['val_acc'].append(epoch_acc)\n",
    "            \n",
    "            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.2f}%')\n",
    "            \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "                # ベストモデルの保存\n",
    "                torch.save(best_model_wts, os.path.join('models', f'best_model_temp.pth'))\n",
    "    \n",
    "    time_elapsed = time.time() - start_time\n",
    "    print(f'\\nTraining completed in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.2f}%')\n",
    "    \n",
    "    # 最後にベストなモデルの重みをロード\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history\n",
    "\n",
    "def save_results(model, history, val_loader, surface_type, device):\n",
    "    # 学習履歴のプロット\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Training Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss History ({surface_type})')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Training Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.title(f'Accuracy History ({surface_type})')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join('results', f'training_history_{surface_type}.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # モデルの評価\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc='Evaluating'):\n",
    "            try:\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.numpy())\n",
    "            except Exception as e:\n",
    "                print(f\"Error in evaluation batch: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    # 混同行列の生成と保存\n",
    "    try:\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=['No Crack', 'Crack'],\n",
    "                    yticklabels=['No Crack', 'Crack'])\n",
    "        plt.title(f'Confusion Matrix ({surface_type})')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.savefig(os.path.join('results', f'confusion_matrix_{surface_type}.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        # 分類レポートの保存\n",
    "        report = classification_report(all_labels, all_preds, \n",
    "                                     target_names=['No Crack', 'Crack'])\n",
    "        with open(os.path.join('results', f'classification_report_{surface_type}.txt'), 'w') as f:\n",
    "            f.write(report)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in generating evaluation metrics: {str(e)}\")\n",
    "    \n",
    "    # モデルの保存\n",
    "    try:\n",
    "        # ベストモデルをコピー\n",
    "        os.rename(\n",
    "            os.path.join('models', 'best_model_temp.pth'),\n",
    "            os.path.join('models', f'best_model_{surface_type}.pth')\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {str(e)}\")\n",
    "        # 通常のモデル保存を試みる\n",
    "        torch.save(model.state_dict(), os.path.join('models', f'best_model_{surface_type}.pth'))\n",
    "\n",
    "def train_surface_type(surface_type, device):\n",
    "    print(f\"\\nTraining model for surface type: {surface_type}\")\n",
    "    \n",
    "    try:\n",
    "        # データセットの作成\n",
    "        full_dataset = CrackDataset(\n",
    "            train_dir[surface_type]['crack'],\n",
    "            train_dir[surface_type]['uncrack'],\n",
    "            transform=data_transforms['train']\n",
    "        )\n",
    "        \n",
    "        # データセット情報の表示\n",
    "        print(f\"Total images: {len(full_dataset)}\")\n",
    "        crack_count = sum(1 for label in full_dataset.labels if label == 1)\n",
    "        no_crack_count = sum(1 for label in full_dataset.labels if label == 0)\n",
    "        print(f\"Crack images: {crack_count}\")\n",
    "        print(f\"No crack images: {no_crack_count}\")\n",
    "        \n",
    "        # データセットの分割\n",
    "        train_size = int(0.8 * len(full_dataset))\n",
    "        val_size = len(full_dataset) - train_size\n",
    "        train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "        \n",
    "        # DataLoaderの作成\n",
    "        train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "        \n",
    "        dataloaders = {\n",
    "            'train': train_loader,\n",
    "            'val': val_loader\n",
    "        }\n",
    "        \n",
    "        # モデルの設定\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_ftrs, 2)\n",
    "        )\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # 損失関数とオプティマイザの設定\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "        \n",
    "        # モデルの訓練\n",
    "        model, history = train_model(\n",
    "            model, dataloaders, criterion, optimizer, scheduler, device, num_epochs=2\n",
    "        )\n",
    "        \n",
    "        # 結果の保存\n",
    "        save_results(model, history, val_loader, surface_type, device)\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error training surface type {surface_type}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # GPU/MPS/CPUの設定\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"Using CUDA\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    \n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"Device: {device}\")\n",
    "    \n",
    "    # データディレクトリの確認\n",
    "    if not os.path.exists(data_dir):\n",
    "        raise FileNotFoundError(f\"Data directory '{data_dir}' not found!\")\n",
    "    \n",
    "    # トレーニングの実行\n",
    "    for surface_type in ['D', 'P', 'W']:\n",
    "        try:\n",
    "            model = train_surface_type(surface_type, device)\n",
    "            if model is not None:\n",
    "                print(f\"Successfully trained model for {surface_type}\")\n",
    "            else:\n",
    "                print(f\"Failed to train model for {surface_type}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fatal error training {surface_type}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
